{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pa49bUnKyRgF"
   },
   "source": [
    "# DeepShake Multi-step Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GU8C5qm_4vZb"
   },
   "source": [
    "This notebook is a template for doing time series forecasting on the Ridgecrest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import py3nvml\n",
    "sys.path.append(\"./networks/.\")\n",
    "sys.path.append(\"../utils/.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "import py3nvml\n",
    "\n",
    "from utils import *\n",
    "from lstm import *\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ad9697/anaconda3/envs/tf_gpu/bin/python\n",
      "/home/ad9697/anaconda3/envs/tf_gpu/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9780469349221575831\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8793741564515968265\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 989396992\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 87586972099026135\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:07:00.0, compute capability: 3.7\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 989396992\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 12358119886736743279\n",
      "physical_device_desc: \"device: 1, name: Tesla K80, pci bus id: 0000:08:00.0, compute capability: 3.7\"\n",
      ", name: \"/device:GPU:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11328123700\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 13797185737647078551\n",
      "physical_device_desc: \"device: 2, name: Tesla K80, pci bus id: 0000:0e:00.0, compute capability: 3.7\"\n",
      ", name: \"/device:GPU:3\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1132003328\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 14685451452112935561\n",
      "physical_device_desc: \"device: 3, name: Tesla K80, pci bus id: 0000:0f:00.0, compute capability: 3.7\"\n",
      ", name: \"/device:GPU:4\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 989396992\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 5\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 6\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 7\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 10458674736528266544\n",
      "physical_device_desc: \"device: 4, name: Tesla K80, pci bus id: 0000:87:00.0, compute capability: 3.7\"\n",
      ", name: \"/device:GPU:5\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 989396992\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 4\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 6\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 7\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 5195769903219207239\n",
      "physical_device_desc: \"device: 5, name: Tesla K80, pci bus id: 0000:88:00.0, compute capability: 3.7\"\n",
      ", name: \"/device:GPU:6\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1132003328\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 4\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 5\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 7\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 18194051282839353538\n",
      "physical_device_desc: \"device: 6, name: Tesla K80, pci bus id: 0000:8e:00.0, compute capability: 3.7\"\n",
      ", name: \"/device:GPU:7\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 203882496\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 4\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 5\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 6\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 8038665824818745763\n",
      "physical_device_desc: \"device: 7, name: Tesla K80, pci bus id: 0000:8f:00.0, compute capability: 3.7\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 92115259860847739\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 18131477286361366127\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:2\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4368746989474928963\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:3\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13384287423217384050\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:4\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15117348757007875490\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:5\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8992343645622428973\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:6\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5802436197019204762\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:7\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13154672668588279170\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "\n",
    "# print(py3nvml.grab_gpus(1))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 17 14:50:33 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   74C    P0   142W / 149W |  10274MiB / 11441MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   56C    P0   137W / 149W |  10274MiB / 11441MiB |     98%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    60W / 149W |     71MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    74W / 149W |  10138MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla K80           On   | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   77C    P0   147W / 149W |  10274MiB / 11441MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla K80           On   | 00000000:88:00.0 Off |                    0 |\n",
      "| N/A   56C    P0   144W / 149W |  10274MiB / 11441MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla K80           On   | 00000000:8E:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    61W / 149W |  10138MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla K80           On   | 00000000:8F:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    72W / 149W |  11023MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      2083      C   ...ad9697/anaconda3/envs/tf_gpu/bin/python    58MiB |\n",
      "|    0     29409      C   python                                     10203MiB |\n",
      "|    1      2083      C   ...ad9697/anaconda3/envs/tf_gpu/bin/python    58MiB |\n",
      "|    1     29582      C   python                                     10203MiB |\n",
      "|    2      2083      C   ...ad9697/anaconda3/envs/tf_gpu/bin/python    58MiB |\n",
      "|    3      2083      C   ...ad9697/anaconda3/envs/tf_gpu/bin/python    58MiB |\n",
      "|    4      2083      C   ...ad9697/anaconda3/envs/tf_gpu/bin/python    58MiB |\n",
      "|    4     54819      C   python                                     10203MiB |\n",
      "|    5      2083      C   ...ad9697/anaconda3/envs/tf_gpu/bin/python    58MiB |\n",
      "|    5     54989      C   python                                     10203MiB |\n",
      "|    6      2083      C   ...ad9697/anaconda3/envs/tf_gpu/bin/python    58MiB |\n",
      "|    6     60747      C   python                                     10067MiB |\n",
      "|    7      2083      C   ...ad9697/anaconda3/envs/tf_gpu/bin/python    58MiB |\n",
      "|    7     53027      C   /home/zhuwq/.local/miniconda3/bin/python   10952MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "py3nvml.grab_gpus(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TokBlnUhWFw9"
   },
   "source": [
    "## The Ridgecrest Dataset and parsed data\n",
    "This notebook uses a earthquake dataset from Ridgecrest, collected from July to September of 2019.\n",
    "There are several thousand earthquakes during this time period, which were collected at anywhere from 16-30 stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stations = 15\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/histStat_norm_class\"\n",
    "\n",
    "x_train_multi = np.load(os.path.join(data_path, \"X_train_histnorm.npy\"))\n",
    "x_val_multi = np.load(os.path.join(data_path, \"X_val_histnorm.npy\"))\n",
    "\n",
    "y_train_labels = np.load(os.path.join(data_path, \"y_train_labels.npy\"))\n",
    "y_val_labels = np.load(os.path.join(data_path, \"y_val_labels.npy\"))\n",
    "\n",
    "train_mean = np.squeeze(np.load(os.path.join(data_path, \"mean_train_histnorm.npy\")))\n",
    "train_std =  np.squeeze(np.load(os.path.join(data_path, \"std_train_histnorm.npy\")))\n",
    "\n",
    "val_mean = np.squeeze(np.load(os.path.join(data_path, \"mean_val_histnorm.npy\")))\n",
    "val_std =  np.squeeze(np.load(os.path.join(data_path, \"std_val_histnorm.npy\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.55743769e-01 3.04186116e-01 1.33853874e+00 6.70023474e+00\n",
      " 6.25942982e+01 1.18929167e+03]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train_labels), y_train_labels)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((999005, 15), (999005, 15), (249760, 15), (249760, 15))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean.shape, train_std.shape, val_mean.shape, val_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_scaler = preprocessing.StandardScaler().fit(x_train_multi)\n",
    "mean_scaler = preprocessing.StandardScaler().fit(train_mean)\n",
    "std_scaler = preprocessing.StandardScaler().fit(train_std)\n",
    "\n",
    "# x_train_multi = X_scaler.transform(x_train_multi)\n",
    "mean_scaled_train = mean_scaler.transform(train_mean)\n",
    "std_scaled_train = std_scaler.transform(train_std)\n",
    "\n",
    "# x_val_multi = X_scaler.transform(x_val_multi)\n",
    "mean_scaled_val = mean_scaler.transform(val_mean)\n",
    "std_scaled_val = std_scaler.transform(val_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999005, 15) (249760, 15)\n"
     ]
    }
   ],
   "source": [
    "print(mean_scaled_train.shape, mean_scaled_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config_path = os.path.join(data_path, \"config.json\")\n",
    "with open(config_path) as json_file:\n",
    "    config = json.load(json_file)\n",
    "    \n",
    "_, past_history, STEP, future_target= list(config.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GnE087bJYSu"
   },
   "source": [
    "### Model with normalized log(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Original Definition\n",
    "from tensorflow.keras.layers import LSTM, Dense, concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "#Temporal sub-network for log(acc) \n",
    "tseries_in = Input(shape=x_train_multi.shape[1:])\n",
    "tseries = LSTM(128, return_sequences=True, input_shape=x_train_multi.shape[1:], name='LSTM1')(tseries_in)\n",
    "tseries = LSTM(64, return_sequences=True, activation='relu', name='LSTM2')(tseries)\n",
    "tseries = LSTM(64, activation='relu', name='LSTM3')(tseries)\n",
    "tseries = Dense(32, activation='relu', name='Dense_tseries')(tseries)\n",
    "# model1 = Model(tseries_in, tseries)\n",
    "\n",
    "size1_in = Input(train_mean.shape[1:])\n",
    "size1 = Dense(16, activation='relu', name=\"Dense_mean\")(size1_in)\n",
    "# size_model1 = Model(size1_in, size1)\n",
    "\n",
    "size2_in = Input(train_mean.shape[1:])\n",
    "size2 = Dense(16, activation='relu', name=\"Dense_std\")(size2_in)\n",
    "# size_model2 = Model(size2_in, size2)\n",
    "\n",
    "size_branches = concatenate([size1, size2])\n",
    "size_branches = Dense(32, activation='relu', name=\"Dense_size\")(size_branches)\n",
    "\n",
    "branches_concat = concatenate([tseries, size_branches])\n",
    "\n",
    "out = Dense(32, activation='relu', name='merged_1')(branches_concat)\n",
    "\n",
    "out = Dense(num_classes, activation='softmax', name='merged_out')(out)\n",
    "\n",
    "model = Model(inputs = [tseries_in, size1_in, size2_in], outputs = [out], name=\"Quake_classifier\")\n",
    "\n",
    "\n",
    "model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,CSVLogger\n",
    "from keras import optimizers\n",
    "\n",
    "lr = .01\n",
    "BATCH_SIZE=2048\n",
    "save_path = \"./trained_models_acc/classification\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "# cur_file = \"LSTM3_10steps_dropzero\"\n",
    "cur_file = 'classifier_v1'\n",
    "cur_file = os.path.join(save_path, cur_file)\n",
    "\n",
    "opt = optimizers.Nadam(learning_rate=lr, beta_1=0.9, beta_2=0.999)\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0,\n",
    ")\n",
    "model_check = ModelCheckpoint(cur_file + '.h5', monitor='val_loss', verbose=1, save_best_only=True, \n",
    "                              save_weights_only=True, mode='min')\n",
    "csv_log = CSVLogger(cur_file+ '_history.csv')\n",
    "callback_list = [early_stop, reduce_lr, model_check, csv_log]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvB7zBqVSMyl"
   },
   "source": [
    "Let's see how the model predicts before it trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13_ZWvB9SRlZ"
   },
   "outputs": [],
   "source": [
    "print(model.predict([x_val_multi[0:1], mean_scaled_val[0:1], std_scaled_val[0:1]], batch_size = BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uwOhXo3Oems"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "model_history = model.fit([x_train_multi, mean_scaled_train, std_scaled_train], \n",
    "                                          y_train_labels, \n",
    "                                          epochs=EPOCHS,\n",
    "                                          validation_data=([x_val_multi, mean_scaled_val, std_scaled_val], y_val_labels),\n",
    "                                          class_weight = class_weights,\n",
    "                                          batch_size = BATCH_SIZE, \n",
    "                                          callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKfQoBjQ5l7U"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_history(model_history, 'Classification Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(cur_file + '.h5')\n",
    "\n",
    "preds = model.predict([x_val_multi, mean_scaled_val, std_scaled_val])\n",
    "print(preds.shape, preds.max(), preds.min())\n",
    "\n",
    "np.save(os.path.join(save_path, 'val_preds.npy'), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without normalized log(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/histStat_norm_class\"\n",
    "\n",
    "x_train_multi = np.load(os.path.join(data_path, \"X_train_unnorm.npy\"))\n",
    "x_val_multi = np.load(os.path.join(data_path, \"X_val_unnorm.npy\"))\n",
    "\n",
    "y_train_labels = np.load(os.path.join(data_path, \"y_train_labels.npy\"))\n",
    "y_val_labels = np.load(os.path.join(data_path, \"y_val_labels.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Unnorm_Quake_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 15, 15)]          0         \n",
      "_________________________________________________________________\n",
      "LSTM1 (LSTM)                 (None, 15, 128)           73728     \n",
      "_________________________________________________________________\n",
      "LSTM2 (LSTM)                 (None, 15, 64)            49408     \n",
      "_________________________________________________________________\n",
      "LSTM3 (LSTM)                 (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "Dense_tseries (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "Dense_out (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 158,438\n",
      "Trainable params: 158,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ## Original Definition\n",
    "from tensorflow.keras.layers import LSTM, Dense, concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "## Unnorm model\n",
    "#Temporal sub-network for log(acc) \n",
    "tseries_in = Input(shape=x_train_multi.shape[1:])\n",
    "tseries = LSTM(128, return_sequences=True, input_shape=x_train_multi.shape[1:], name='LSTM1')(tseries_in)\n",
    "tseries = LSTM(64, return_sequences=True, activation='relu', name='LSTM2')(tseries)\n",
    "tseries = LSTM(64, activation='relu', name='LSTM3')(tseries)\n",
    "tseries = Dense(32, activation='relu', name='Dense_tseries')(tseries)\n",
    "tseries = Dense(num_classes, activation='softmax', name='Dense_out')(tseries)\n",
    "\n",
    "unnorm_model = Model(tseries_in, tseries, name=\"Unnorm_Quake_classifier\")\n",
    "\n",
    "unnorm_model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
    "unnorm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,CSVLogger\n",
    "from keras import optimizers\n",
    "\n",
    "lr = .01\n",
    "BATCH_SIZE=2048\n",
    "save_path = \"./trained_models_acc/classification\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "# cur_file = \"LSTM3_10steps_dropzero\"\n",
    "cur_file = 'classifier_v1_unnorm'\n",
    "cur_file = os.path.join(save_path, cur_file)\n",
    "\n",
    "opt = optimizers.Nadam(learning_rate=lr, beta_1=0.9, beta_2=0.999)\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0,\n",
    ")\n",
    "model_check = ModelCheckpoint(cur_file + '.h5', monitor='val_loss', verbose=1, save_best_only=True, \n",
    "                              save_weights_only=True, mode='min')\n",
    "csv_log = CSVLogger(cur_file+ '_history.csv')\n",
    "callback_list = [early_stop, reduce_lr, model_check, csv_log]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 999005 samples, validate on 249760 samples\n",
      "Epoch 1/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.8759 - accuracy: 0.5883\n",
      "Epoch 00001: val_loss improved from inf to 0.70007, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 122s 122us/sample - loss: 0.8756 - accuracy: 0.5884 - val_loss: 0.7001 - val_accuracy: 0.6878\n",
      "Epoch 2/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.7107 - accuracy: 0.6679\n",
      "Epoch 00002: val_loss improved from 0.70007 to 0.63307, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.7106 - accuracy: 0.6680 - val_loss: 0.6331 - val_accuracy: 0.7213\n",
      "Epoch 3/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.6809 - accuracy: 0.6884\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.63307\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.6809 - accuracy: 0.6884 - val_loss: 0.7431 - val_accuracy: 0.6444\n",
      "Epoch 4/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.6032 - accuracy: 0.7412\n",
      "Epoch 00004: val_loss improved from 0.63307 to 0.57167, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.6032 - accuracy: 0.7412 - val_loss: 0.5717 - val_accuracy: 0.7581\n",
      "Epoch 5/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.5875 - accuracy: 0.7490\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.57167\n",
      "999005/999005 [==============================] - 116s 117us/sample - loss: 0.5875 - accuracy: 0.7490 - val_loss: 0.5864 - val_accuracy: 0.7438\n",
      "Epoch 6/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.5559 - accuracy: 0.7688\n",
      "Epoch 00006: val_loss improved from 0.57167 to 0.56121, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.5560 - accuracy: 0.7688 - val_loss: 0.5612 - val_accuracy: 0.7561\n",
      "Epoch 7/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.5426 - accuracy: 0.7742\n",
      "Epoch 00007: val_loss improved from 0.56121 to 0.54693, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.5427 - accuracy: 0.7742 - val_loss: 0.5469 - val_accuracy: 0.7650\n",
      "Epoch 8/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.5320 - accuracy: 0.7792\n",
      "Epoch 00008: val_loss improved from 0.54693 to 0.52056, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.5320 - accuracy: 0.7792 - val_loss: 0.5206 - val_accuracy: 0.7842\n",
      "Epoch 9/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.5237 - accuracy: 0.7832\n",
      "Epoch 00009: val_loss improved from 0.52056 to 0.51857, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.5237 - accuracy: 0.7832 - val_loss: 0.5186 - val_accuracy: 0.7835\n",
      "Epoch 10/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.5171 - accuracy: 0.7865\n",
      "Epoch 00010: val_loss improved from 0.51857 to 0.51289, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.5170 - accuracy: 0.7865 - val_loss: 0.5129 - val_accuracy: 0.7867\n",
      "Epoch 11/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.5111 - accuracy: 0.7892\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.51289\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.5111 - accuracy: 0.7892 - val_loss: 0.5130 - val_accuracy: 0.7873\n",
      "Epoch 12/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4965 - accuracy: 0.7970\n",
      "Epoch 00012: val_loss improved from 0.51289 to 0.49966, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4965 - accuracy: 0.7970 - val_loss: 0.4997 - val_accuracy: 0.7954\n",
      "Epoch 13/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4943 - accuracy: 0.7978\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.49966\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4943 - accuracy: 0.7978 - val_loss: 0.5024 - val_accuracy: 0.7933\n",
      "Epoch 14/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4880 - accuracy: 0.8008\n",
      "Epoch 00014: val_loss improved from 0.49966 to 0.49546, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4881 - accuracy: 0.8008 - val_loss: 0.4955 - val_accuracy: 0.7968\n",
      "Epoch 15/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4865 - accuracy: 0.8015\n",
      "Epoch 00015: val_loss improved from 0.49546 to 0.49305, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4866 - accuracy: 0.8015 - val_loss: 0.4931 - val_accuracy: 0.7975\n",
      "Epoch 16/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4853 - accuracy: 0.8017\n",
      "Epoch 00016: val_loss improved from 0.49305 to 0.49254, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4853 - accuracy: 0.8017 - val_loss: 0.4925 - val_accuracy: 0.7976\n",
      "Epoch 17/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4839 - accuracy: 0.8023\n",
      "Epoch 00017: val_loss improved from 0.49254 to 0.49115, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4839 - accuracy: 0.8023 - val_loss: 0.4912 - val_accuracy: 0.7983\n",
      "Epoch 18/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4828 - accuracy: 0.8028\n",
      "Epoch 00018: val_loss improved from 0.49115 to 0.49042, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4827 - accuracy: 0.8028 - val_loss: 0.4904 - val_accuracy: 0.7989\n",
      "Epoch 19/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4815 - accuracy: 0.8035\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.49042\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4815 - accuracy: 0.8035 - val_loss: 0.4923 - val_accuracy: 0.7985\n",
      "Epoch 20/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4793 - accuracy: 0.8046\n",
      "Epoch 00020: val_loss improved from 0.49042 to 0.48974, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4792 - accuracy: 0.8046 - val_loss: 0.4897 - val_accuracy: 0.7995\n",
      "Epoch 21/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4786 - accuracy: 0.8047\n",
      "Epoch 00021: val_loss improved from 0.48974 to 0.48803, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 116s 116us/sample - loss: 0.4786 - accuracy: 0.8047 - val_loss: 0.4880 - val_accuracy: 0.7997\n",
      "Epoch 22/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.8049\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.48803\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4781 - accuracy: 0.8049 - val_loss: 0.4881 - val_accuracy: 0.7995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4770 - accuracy: 0.8054\n",
      "Epoch 00023: val_loss improved from 0.48803 to 0.48676, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4770 - accuracy: 0.8054 - val_loss: 0.4868 - val_accuracy: 0.8006\n",
      "Epoch 24/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4767 - accuracy: 0.8055\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.48676\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4767 - accuracy: 0.8055 - val_loss: 0.4873 - val_accuracy: 0.8001\n",
      "Epoch 25/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4762 - accuracy: 0.8058\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.48676 to 0.48675, saving model to ./trained_models_acc/classification/classifier_v1_unnorm.h5\n",
      "999005/999005 [==============================] - 117s 117us/sample - loss: 0.4762 - accuracy: 0.8058 - val_loss: 0.4867 - val_accuracy: 0.8005\n",
      "Epoch 26/50\n",
      "509952/999005 [==============>...............] - ETA: 53s - loss: 0.4751 - accuracy: 0.8062"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "unnorm_model_history = unnorm_model.fit(x_train_multi, \n",
    "                                          y_train_labels, \n",
    "                                          epochs=EPOCHS,\n",
    "                                          validation_data=(x_val_multi, y_val_labels),\n",
    "                                          class_weight = class_weights,\n",
    "                                          batch_size = BATCH_SIZE, \n",
    "                                          callbacks=callback_list,\n",
    "                                           shuffle=True\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249760, 6) 1.0 7.657487e-35\n"
     ]
    }
   ],
   "source": [
    "unnorm_model.load_weights(cur_file + '.h5')\n",
    "\n",
    "preds = unnorm_model.predict(x_val_multi)\n",
    "print(preds.shape, preds.max(), preds.min())\n",
    "\n",
    "np.save(os.path.join(save_path, 'val_preds_unnorm.npy'), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model not trained on tseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/histStat_norm_class\"\n",
    "\n",
    "y_train_labels = np.load(os.path.join(data_path, \"y_train_labels.npy\"))\n",
    "y_val_labels = np.load(os.path.join(data_path, \"y_val_labels.npy\"))\n",
    "\n",
    "train_mean = np.squeeze(np.load(os.path.join(data_path, \"mean_train_histnorm.npy\")))\n",
    "train_std =  np.squeeze(np.load(os.path.join(data_path, \"std_train_histnorm.npy\")))\n",
    "\n",
    "val_mean = np.squeeze(np.load(os.path.join(data_path, \"mean_val_histnorm.npy\")))\n",
    "val_std =  np.squeeze(np.load(os.path.join(data_path, \"std_val_histnorm.npy\")))\n",
    "\n",
    "\n",
    "mean_scaler = preprocessing.StandardScaler().fit(train_mean)\n",
    "std_scaler = preprocessing.StandardScaler().fit(train_std)\n",
    "\n",
    "# x_train_multi = X_scaler.transform(x_train_multi)\n",
    "mean_scaled_train = mean_scaler.transform(train_mean)\n",
    "std_scaled_train = std_scaler.transform(train_std)\n",
    "\n",
    "# x_val_multi = X_scaler.transform(x_val_multi)\n",
    "mean_scaled_val = mean_scaler.transform(val_mean)\n",
    "std_scaled_val = std_scaler.transform(val_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nontemporal_Quake_classifier\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Dense_mean (Dense)              (None, 16)           256         input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Dense_std (Dense)               (None, 16)           256         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32)           0           Dense_mean[0][0]                 \n",
      "                                                                 Dense_std[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Dense_size (Dense)              (None, 64)           2112        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Dense_size_2 (Dense)            (None, 32)           2080        Dense_size[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merged_out (Dense)              (None, 6)            198         Dense_size_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,902\n",
      "Trainable params: 4,902\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ## Original Definition\n",
    "from tensorflow.keras.layers import LSTM, Dense, concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "size1_in = Input(train_mean.shape[1:])\n",
    "size1 = Dense(16, activation='relu', name=\"Dense_mean\")(size1_in)\n",
    "# size_model1 = Model(size1_in, size1)\n",
    "\n",
    "size2_in = Input(train_mean.shape[1:])\n",
    "size2 = Dense(16, activation='relu', name=\"Dense_std\")(size2_in)\n",
    "# size_model2 = Model(size2_in, size2)\n",
    "\n",
    "size_branches = concatenate([size1, size2])\n",
    "size_branches = Dense(64, activation='relu', name=\"Dense_size\")(size_branches)\n",
    "size_branches = Dense(32, activation='relu', name=\"Dense_size_2\")(size_branches)\n",
    "\n",
    "out = Dense(num_classes, activation='softmax', name='merged_out')(size_branches)\n",
    "\n",
    "model_nontemporal = Model(inputs = [size1_in, size2_in], outputs = [out], name=\"Nontemporal_Quake_classifier\")\n",
    "\n",
    "\n",
    "model_nontemporal.compile(optimizer='nadam', loss='sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
    "model_nontemporal.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,CSVLogger\n",
    "from keras import optimizers\n",
    "\n",
    "lr = .01\n",
    "BATCH_SIZE=2048\n",
    "save_path = \"./trained_models_acc/classification\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "# cur_file = \"LSTM3_10steps_dropzero\"\n",
    "cur_file = 'classifier_v1_nontemporal'\n",
    "cur_file = os.path.join(save_path, cur_file)\n",
    "\n",
    "opt = optimizers.Nadam(learning_rate=lr, beta_1=0.9, beta_2=0.999)\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0,\n",
    ")\n",
    "model_check = ModelCheckpoint(cur_file + '.h5', monitor='val_loss', verbose=1, save_best_only=True, \n",
    "                              save_weights_only=True, mode='min')\n",
    "csv_log = CSVLogger(cur_file+ '_history.csv')\n",
    "callback_list = [early_stop, reduce_lr, model_check, csv_log]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 999005 samples, validate on 249760 samples\n",
      "Epoch 1/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.6901 - accuracy: 0.7268\n",
      "Epoch 00001: val_loss improved from inf to 0.57042, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 14s 14us/sample - loss: 0.6895 - accuracy: 0.7270 - val_loss: 0.5704 - val_accuracy: 0.7650\n",
      "Epoch 2/50\n",
      "991232/999005 [============================>.] - ETA: 0s - loss: 0.5585 - accuracy: 0.7714\n",
      "Epoch 00002: val_loss improved from 0.57042 to 0.54332, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5583 - accuracy: 0.7715 - val_loss: 0.5433 - val_accuracy: 0.7762\n",
      "Epoch 3/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.5393 - accuracy: 0.7783\n",
      "Epoch 00003: val_loss improved from 0.54332 to 0.53377, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 14s 14us/sample - loss: 0.5392 - accuracy: 0.7783 - val_loss: 0.5338 - val_accuracy: 0.7789\n",
      "Epoch 4/50\n",
      "991232/999005 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.7819\n",
      "Epoch 00004: val_loss improved from 0.53377 to 0.52542, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5298 - accuracy: 0.7819 - val_loss: 0.5254 - val_accuracy: 0.7821\n",
      "Epoch 5/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.5233 - accuracy: 0.7841\n",
      "Epoch 00005: val_loss improved from 0.52542 to 0.52199, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5233 - accuracy: 0.7841 - val_loss: 0.5220 - val_accuracy: 0.7837\n",
      "Epoch 6/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.5185 - accuracy: 0.7862\n",
      "Epoch 00006: val_loss improved from 0.52199 to 0.52001, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5184 - accuracy: 0.7862 - val_loss: 0.5200 - val_accuracy: 0.7838\n",
      "Epoch 7/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.5145 - accuracy: 0.7877\n",
      "Epoch 00007: val_loss improved from 0.52001 to 0.51541, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 12s 12us/sample - loss: 0.5145 - accuracy: 0.7877 - val_loss: 0.5154 - val_accuracy: 0.7866\n",
      "Epoch 8/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.5110 - accuracy: 0.7891\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.51541 to 0.51532, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5110 - accuracy: 0.7891 - val_loss: 0.5153 - val_accuracy: 0.7860\n",
      "Epoch 9/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.5073 - accuracy: 0.7906\n",
      "Epoch 00009: val_loss improved from 0.51532 to 0.51116, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 17s 17us/sample - loss: 0.5073 - accuracy: 0.7906 - val_loss: 0.5112 - val_accuracy: 0.7888\n",
      "Epoch 10/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.5060 - accuracy: 0.7914\n",
      "Epoch 00010: val_loss improved from 0.51116 to 0.50984, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5059 - accuracy: 0.7914 - val_loss: 0.5098 - val_accuracy: 0.7893\n",
      "Epoch 11/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.5047 - accuracy: 0.7918\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.50984\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5047 - accuracy: 0.7918 - val_loss: 0.5106 - val_accuracy: 0.7894\n",
      "Epoch 12/50\n",
      "995328/999005 [============================>.] - ETA: 0s - loss: 0.5031 - accuracy: 0.7923\n",
      "Epoch 00012: val_loss improved from 0.50984 to 0.50852, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 11s 11us/sample - loss: 0.5031 - accuracy: 0.7923 - val_loss: 0.5085 - val_accuracy: 0.7901\n",
      "Epoch 13/50\n",
      "995328/999005 [============================>.] - ETA: 0s - loss: 0.5025 - accuracy: 0.7927\n",
      "Epoch 00013: val_loss improved from 0.50852 to 0.50838, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5025 - accuracy: 0.7928 - val_loss: 0.5084 - val_accuracy: 0.7901\n",
      "Epoch 14/50\n",
      "991232/999005 [============================>.] - ETA: 0s - loss: 0.5019 - accuracy: 0.7931\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.50838\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5019 - accuracy: 0.7931 - val_loss: 0.5087 - val_accuracy: 0.7907\n",
      "Epoch 15/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.5011 - accuracy: 0.7933\n",
      "Epoch 00015: val_loss improved from 0.50838 to 0.50737, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5011 - accuracy: 0.7933 - val_loss: 0.5074 - val_accuracy: 0.7906\n",
      "Epoch 16/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.5008 - accuracy: 0.7936\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.50737\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5008 - accuracy: 0.7936 - val_loss: 0.5076 - val_accuracy: 0.7909\n",
      "Epoch 17/50\n",
      "995328/999005 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.7936\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.50737\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5004 - accuracy: 0.7936 - val_loss: 0.5074 - val_accuracy: 0.7910\n",
      "Epoch 18/50\n",
      "995328/999005 [============================>.] - ETA: 0s - loss: 0.5002 - accuracy: 0.7938\n",
      "Epoch 00018: val_loss improved from 0.50737 to 0.50726, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5001 - accuracy: 0.7938 - val_loss: 0.5073 - val_accuracy: 0.7910\n",
      "Epoch 19/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.5000 - accuracy: 0.7938\n",
      "Epoch 00019: val_loss improved from 0.50726 to 0.50713, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5001 - accuracy: 0.7938 - val_loss: 0.5071 - val_accuracy: 0.7913\n",
      "Epoch 20/50\n",
      "995328/999005 [============================>.] - ETA: 0s - loss: 0.5000 - accuracy: 0.7938\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.50713\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.5000 - accuracy: 0.7938 - val_loss: 0.5073 - val_accuracy: 0.7912\n",
      "Epoch 21/50\n",
      "991232/999005 [============================>.] - ETA: 0s - loss: 0.4998 - accuracy: 0.7939\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.50713 to 0.50710, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.4999 - accuracy: 0.7939 - val_loss: 0.5071 - val_accuracy: 0.7913\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.4998 - accuracy: 0.7939\n",
      "Epoch 00022: val_loss improved from 0.50710 to 0.50698, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.4998 - accuracy: 0.7939 - val_loss: 0.5070 - val_accuracy: 0.7912\n",
      "Epoch 23/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.4998 - accuracy: 0.7939\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.50698 to 0.50693, saving model to ./trained_models_acc/classification/classifier_v1_nontemporal.h5\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.4998 - accuracy: 0.7939 - val_loss: 0.5069 - val_accuracy: 0.7913\n",
      "Epoch 24/50\n",
      "993280/999005 [============================>.] - ETA: 0s - loss: 0.4998 - accuracy: 0.7939\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.50693\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.4997 - accuracy: 0.7939 - val_loss: 0.5070 - val_accuracy: 0.7913\n",
      "Epoch 25/50\n",
      "995328/999005 [============================>.] - ETA: 0s - loss: 0.4997 - accuracy: 0.7939\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.50693\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.4997 - accuracy: 0.7939 - val_loss: 0.5070 - val_accuracy: 0.7912\n",
      "Epoch 26/50\n",
      "997376/999005 [============================>.] - ETA: 0s - loss: 0.4997 - accuracy: 0.7939Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.50693\n",
      "999005/999005 [==============================] - 10s 10us/sample - loss: 0.4997 - accuracy: 0.7939 - val_loss: 0.5070 - val_accuracy: 0.7913\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model_nontemporal_history = model_nontemporal.fit([mean_scaled_train, std_scaled_train], \n",
    "                                          y_train_labels, \n",
    "                                          epochs=EPOCHS,\n",
    "                                          validation_data=([mean_scaled_val, std_scaled_val], y_val_labels),\n",
    "                                          class_weight = class_weights,\n",
    "                                          batch_size = BATCH_SIZE, \n",
    "                                          callbacks=callback_list,\n",
    "                                           shuffle=True\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249760, 6) 0.998317 2.1381644e-10\n"
     ]
    }
   ],
   "source": [
    "model_nontemporal.load_weights(cur_file + '.h5')\n",
    "\n",
    "preds = model_nontemporal.predict([mean_scaled_val, std_scaled_val])\n",
    "print(preds.shape, preds.max(), preds.min())\n",
    "\n",
    "np.save(os.path.join(save_path, 'val_preds_nontemporal.npy'), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "private_outputs": true,
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
